{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Text Classification\n",
    "\n",
    "# *Classificador de Spam*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS as stopwords\n",
    "import unicodedata\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GroupKFold , RandomizedSearchCV , KFold , cross_validate, cross_val_score, train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from scipy.stats import randint\n",
    "from spacy.lang.en.stop_words import STOP_WORDS as stopwords\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Spam Dataset\n",
    "### *Carregando o Banco de Dados*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('spam.csv', encoding='latin-1')\n",
    "del df['Unnamed: 2']\n",
    "del df['Unnamed: 3']\n",
    "del df['Unnamed: 4']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v1    0\n",
       "v2    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sorry, I'll call later                                                                                                                                                 30\n",
       "I cant pick the phone right now. Pls send a message                                                                                                                    12\n",
       "Ok...                                                                                                                                                                  10\n",
       "7 wonders in My WORLD 7th You 6th Ur style 5th Ur smile 4th Ur Personality 3rd Ur Nature 2nd Ur SMS and 1st \\Ur Lovely Friendship\\\"... good morning dear\"               4\n",
       "Say this slowly.? GOD,I LOVE YOU &amp; I NEED YOU,CLEAN MY HEART WITH YOUR BLOOD.Send this to Ten special people &amp; u c miracle tomorrow, do it,pls,pls do it...     4\n",
       "                                                                                                                                                                       ..\n",
       "I gotta collect da car at 6 lei.                                                                                                                                        1\n",
       "No. On the way home. So if not for the long dry spell the season would have been over                                                                                   1\n",
       "Urgent! Please call 09061743811 from landline. Your ABTA complimentary 4* Tenerife Holiday or å£5000 cash await collection SAE T&Cs Box 326 CW25WX 150ppm               1\n",
       "Dear 0776xxxxxxx U've been invited to XCHAT. This is our final attempt to contact u! Txt CHAT to 86688 150p/MsgrcvdHG/Suite342/2Lands/Row/W1J6HL LDN 18yrs              1\n",
       "Rofl. Its true to its name                                                                                                                                              1\n",
       "Name: v2, Length: 5169, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['v2'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance Dataset\n",
    "### *Balanceando o Banco de Dados*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    v1                                                 v2\n",
       "0  ham  Go until jurong point, crazy.. Available only ...\n",
       "1  ham                      Ok lar... Joking wif u oni...\n",
       "3  ham  U dun say so early hor... U c already then say...\n",
       "4  ham  Nah I don't think he goes to usf, he lives aro...\n",
       "6  ham  Even my brother is not like to speak with me. ..."
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham = df[df['v1']=='ham']\n",
    "ham.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>spam</td>\n",
       "      <td>SIX chances to win CASH! From 100 to 20,000 po...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      v1                                                 v2\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "5   spam  FreeMsg Hey there darling it's been 3 week's n...\n",
       "8   spam  WINNER!! As a valued network customer you have...\n",
       "9   spam  Had your mobile 11 months or more? U R entitle...\n",
       "11  spam  SIX chances to win CASH! From 100 to 20,000 po..."
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam = df[df['v1']=='spam']\n",
    "spam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4825, 2), (747, 2))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham.shape, spam.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham = ham.sample(spam.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((747, 2), (747, 2))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham.shape, spam.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ham.append(spam, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>spam</td>\n",
       "      <td>Camera - You are awarded a SiPix Digital Camer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>ham</td>\n",
       "      <td>Lets use it next week, princess :)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>ham</td>\n",
       "      <td>That is wondar full flim.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>ham</td>\n",
       "      <td>Anything lor... U decide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>ham</td>\n",
       "      <td>Im just wondering what your doing right now?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        v1                                                 v2\n",
       "1466  spam  Camera - You are awarded a SiPix Digital Camer...\n",
       "573    ham                 Lets use it next week, princess :)\n",
       "93     ham                          That is wondar full flim.\n",
       "728    ham                        Anything lor... U decide...\n",
       "431    ham       Im just wondering what your doing right now?"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1494, 2)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     747\n",
       "spam    747\n",
       "Name: v1, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['v1'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré Processamento NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions for process\n",
    "def cont_to_exp(x):\n",
    "    if type(x) is str:\n",
    "        for key in contractions:\n",
    "            value = contractions[key]\n",
    "            x = x.replace(key, value)\n",
    "        return x\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "\n",
    "def make_to_base(x):\n",
    "    x = str(x)\n",
    "    x_list = []\n",
    "    doc = nlp(x)\n",
    "    \n",
    "    for token in doc:\n",
    "        lemma = token.lemma_\n",
    "        if lemma == '-PRON-' or lemma == 'be':\n",
    "            lemma = token.text\n",
    "\n",
    "        x_list.append(lemma)\n",
    "    return ' '.join(x_list)\n",
    "\n",
    "\n",
    "def remove_accented_chars(x):\n",
    "    x = unicodedata.normalize('NFKD', x).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return x\n",
    "\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descri_ process\n",
    "\n",
    "df['num_palavras'] = df['v2'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "#contracoes\n",
    "\n",
    "contractions = { \n",
    "    \"ain't\": \"am not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"can't've\": \"cannot have\",\n",
    "    \"'cause\": \"because\",\n",
    "    \"could've\": \"could have\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"couldn't've\": \"could not have\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"hadn't've\": \"had not have\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"he'd\": \"he would\",\n",
    "    \"he'd've\": \"he would have\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"he'll've\": \"he will have\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"how'd\": \"how did\",\n",
    "    \"how'd'y\": \"how do you\",\n",
    "    \"how'll\": \"how will\",\n",
    "    \"how's\": \"how does\",\n",
    "    \"i'd\": \"i would\",\n",
    "    \"i'd've\": \"i would have\",\n",
    "    \"i'll\": \"i will\",\n",
    "    \"i'll've\": \"i will have\",\n",
    "    \"i'm\": \"i am\",\n",
    "    \"i've\": \"i have\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"it'd\": \"it would\",\n",
    "    \"it'd've\": \"it would have\",\n",
    "    \"it'll\": \"it will\",\n",
    "    \"it'll've\": \"it will have\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"ma'am\": \"madam\",\n",
    "    \"mayn't\": \"may not\",\n",
    "    \"might've\": \"might have\",\n",
    "    \"mightn't\": \"might not\",\n",
    "    \"mightn't've\": \"might not have\",\n",
    "    \"must've\": \"must have\",\n",
    "    \"mustn't\": \"must not\",\n",
    "    \"mustn't've\": \"must not have\",\n",
    "    \"needn't\": \"need not\",\n",
    "    \"needn't've\": \"need not have\",\n",
    "    \"o'clock\": \"of the clock\",\n",
    "    \"oughtn't\": \"ought not\",\n",
    "    \"oughtn't've\": \"ought not have\",\n",
    "    \"shan't\": \"shall not\",\n",
    "    \"sha'n't\": \"shall not\",\n",
    "    \"shan't've\": \"shall not have\",\n",
    "    \"she'd\": \"she would\",\n",
    "    \"she'd've\": \"she would have\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"she'll've\": \"she will have\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"should've\": \"should have\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"shouldn't've\": \"should not have\",\n",
    "    \"so've\": \"so have\",\n",
    "    \"so's\": \"so is\",\n",
    "    \"that'd\": \"that would\",\n",
    "    \"that'd've\": \"that would have\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"there'd\": \"there would\",\n",
    "    \"there'd've\": \"there would have\",\n",
    "    \"there's\": \"there is\",\n",
    "    \"they'd\": \"they would\",\n",
    "    # \"they'd've\": \"they would have\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"they'll've\": \"they will have\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"to've\": \"to have\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \" u \": \" you \",\n",
    "    \" ur \": \" your \",\n",
    "    \" n \": \" and \",\n",
    "    \"won't\": \"would not\",\n",
    "    'dis': 'this',\n",
    "    'bak': 'back',\n",
    "    'brng': 'bring'\n",
    "}\n",
    "\n",
    "# -----\n",
    "\n",
    "df['v2'] = df['v2'].apply(lambda x: cont_to_exp(x))\n",
    "df.dtypes\n",
    "#removendo chracter special\n",
    "df['v2'] = df['v2'].apply(lambda x: re.sub(r'[^\\w ]+', \"\", x))\n",
    "\n",
    "#deixando tudo em lower case\n",
    "df['v2'] = df['v2'].apply(lambda x: str(x).lower())\n",
    "\n",
    "#removendo espacos multiplos\n",
    "df['v2'] = df['v2'].apply(lambda x: ' '.join(x.split())) \n",
    "#esse joint irá juntar as palavras com espaco simples\n",
    "\n",
    "#removendo os acentos\n",
    "df['v2'] = df['v2'].apply(lambda x: remove_accented_chars(x))\n",
    "\n",
    "#removendo as stopwords\n",
    "df['v2'] = df['v2'].apply(lambda x: ' '.join([t for t in x.split() if t not in stopwords]))\n",
    "\n",
    "#transformando na raiz da palavra\n",
    "df['v2'] = df['v2'].apply(lambda x: make_to_base(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo as Variáveis e os Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "x = tfidf.fit_transform(df['v2'])\n",
    "\n",
    "y = df['v1']\n",
    "\n",
    "def imprime_score(scores):\n",
    "  media = scores.mean() * 100\n",
    "  desvio = scores.std() * 100\n",
    "  print(\"Accuracy médio %.2f\" % media)\n",
    "  print(\"Intervalo [%.2f, %.2f]\" % (media - 2 * desvio, media + 2 * desvio))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Dummy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy com dummy stratified, 10 = [86.43, 86.75]\n"
     ]
    }
   ],
   "source": [
    "SEED = 301\n",
    "np.random.seed(SEED)\n",
    "\n",
    "modelo = DummyClassifier()\n",
    "results = cross_validate(modelo, x, y, cv = 10, return_train_score=False)\n",
    "media = results['test_score'].mean()\n",
    "desvio_padrao = results['test_score'].std()\n",
    "print(\"Accuracy com dummy stratified, 10 = [%.2f, %.2f]\" % ((media - 2 * desvio_padrao)*100, (media + 2 * desvio_padrao) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.961 +-(0.011) {'min_samples_split': 16, 'min_samples_leaf': 2, 'max_depth': 30, 'criterion': 'gini'}\n",
      "0.961 +-(0.011) {'min_samples_split': 16, 'min_samples_leaf': 2, 'max_depth': 20, 'criterion': 'gini'}\n",
      "0.960 +-(0.013) {'min_samples_split': 8, 'min_samples_leaf': 2, 'max_depth': 40, 'criterion': 'entropy'}\n",
      "0.960 +-(0.008) {'min_samples_split': 16, 'min_samples_leaf': 2, 'max_depth': 40, 'criterion': 'entropy'}\n",
      "0.959 +-(0.009) {'min_samples_split': 32, 'min_samples_leaf': 4, 'max_depth': 40, 'criterion': 'gini'}\n",
      "0.955 +-(0.010) {'min_samples_split': 8, 'min_samples_leaf': 4, 'max_depth': 20, 'criterion': 'entropy'}\n",
      "0.955 +-(0.011) {'min_samples_split': 8, 'min_samples_leaf': 4, 'max_depth': 30, 'criterion': 'entropy'}\n",
      "0.955 +-(0.010) {'min_samples_split': 32, 'min_samples_leaf': 4, 'max_depth': 40, 'criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "SEED=301\n",
    "np.random.seed(SEED)\n",
    "\n",
    "espaco_de_parametros = {\n",
    "    \"max_depth\" : [20, 30, 40 ],\n",
    "    \"min_samples_split\" : [8, 16, 32],\n",
    "    \"min_samples_leaf\" : [2, 4 ],\n",
    "    \"criterion\" : [\"gini\", \"entropy\"]\n",
    "}\n",
    "\n",
    "busca = RandomizedSearchCV(DecisionTreeClassifier(),\n",
    "                    espaco_de_parametros,\n",
    "                    n_iter = 8,\n",
    "                    cv = KFold(n_splits = 5, shuffle=True),\n",
    "                    random_state = SEED)\n",
    "busca.fit(x, y)\n",
    "resultados = pd.DataFrame(busca.cv_results_)\n",
    "resultados.head()\n",
    "\n",
    "resultados_ordenados_pela_media = resultados.sort_values(\"mean_test_score\", ascending=False)\n",
    "for indice, linha in resultados_ordenados_pela_media.iterrows():\n",
    "  print(\"%.3f +-(%.3f) %s\" % (linha.mean_test_score, linha.std_test_score*2, linha.params))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy médio 95.93\n",
      "Intervalo [95.17, 96.68]\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(busca, x, y, cv = KFold(n_splits=5, shuffle=True))\n",
    "imprime_score(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(max_depth=30, min_samples_leaf=2, min_samples_split=16)\n"
     ]
    }
   ],
   "source": [
    "melhor = busca.best_estimator_\n",
    "print(melhor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.959 +-(0.012) {'n_estimators': 10, 'min_samples_split': 8, 'min_samples_leaf': 2, 'max_depth': 40, 'criterion': 'entropy', 'bootstrap': False}\n",
      "0.950 +-(0.011) {'n_estimators': 50, 'min_samples_split': 8, 'min_samples_leaf': 4, 'max_depth': 30, 'criterion': 'gini', 'bootstrap': False}\n",
      "0.949 +-(0.009) {'n_estimators': 50, 'min_samples_split': 32, 'min_samples_leaf': 4, 'max_depth': 30, 'criterion': 'gini', 'bootstrap': True}\n",
      "0.931 +-(0.011) {'n_estimators': 10, 'min_samples_split': 8, 'min_samples_leaf': 8, 'max_depth': 40, 'criterion': 'entropy', 'bootstrap': True}\n",
      "0.930 +-(0.011) {'n_estimators': 50, 'min_samples_split': 8, 'min_samples_leaf': 2, 'max_depth': 20, 'criterion': 'entropy', 'bootstrap': True}\n"
     ]
    }
   ],
   "source": [
    "SEED=301\n",
    "np.random.seed(SEED)\n",
    "\n",
    "espaco_de_parametros = {\n",
    "    \"n_estimators\" : [10, 50],\n",
    "    \"max_depth\" : [20,30,40],\n",
    "    \"min_samples_split\" : [8, 16, 32],\n",
    "    \"min_samples_leaf\" : [2, 4, 8],\n",
    "    \"bootstrap\" : [True, False],\n",
    "    \"criterion\" : [\"gini\", \"entropy\"]\n",
    "}\n",
    "\n",
    "busca = RandomizedSearchCV(RandomForestClassifier(),\n",
    "                    espaco_de_parametros,\n",
    "                    n_iter = 8,\n",
    "                    cv = KFold(n_splits = 5, shuffle=True))\n",
    "busca.fit(x, y)\n",
    "\n",
    "resultados = pd.DataFrame(busca.cv_results_)\n",
    "resultados.head()\n",
    "\n",
    "resultados_ordenados_pela_media = resultados.sort_values(\"mean_test_score\", ascending=False)\n",
    "for indice, linha in resultados_ordenados_pela_media[:5].iterrows():\n",
    "  print(\"%.3f +-(%.3f) %s\" % (linha.mean_test_score, linha.std_test_score*2, linha.params))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy médio 95.62\n",
      "Intervalo [93.75, 97.49]\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(busca, x, y, cv = KFold(n_splits=5, shuffle=True))\n",
    "imprime_score(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=False, criterion='entropy', max_depth=40,\n",
      "                       min_samples_leaf=2, min_samples_split=8,\n",
      "                       n_estimators=10)\n"
     ]
    }
   ],
   "source": [
    "melhor = busca.best_estimator_\n",
    "print(melhor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maneira Mais simples, mas encontrando otimos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>num_palavras</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>jurong point crazy available bugis great world...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar joke wif oni</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entry 2 wkly comp win fa cup final tkts 2...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun early hor u c</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah think go usf life</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2  num_palavras\n",
       "0   ham  jurong point crazy available bugis great world...            20\n",
       "1   ham                                ok lar joke wif oni             6\n",
       "2  spam  free entry 2 wkly comp win fa cup final tkts 2...            28\n",
       "3   ham                                u dun early hor u c            11\n",
       "4   ham                              nah think go usf life            13"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "X = tfidf.fit_transform(df['v2'])\n",
    "X = X.toarray()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, df['v1'], test_size = 0.2, random_state = 301, stratify = df['v1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4457, 8290), (1115, 8290))"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, n_jobs= -1)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[965,   1],\n",
       "       [ 26, 123]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.99       966\n",
      "        spam       0.99      0.83      0.90       149\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.98      0.91      0.94      1115\n",
      "weighted avg       0.98      0.98      0.97      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(C = 1000, gamma = 'auto')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[965,   1],\n",
       "       [ 42, 107]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.96      1.00      0.98       966\n",
      "        spam       0.99      0.72      0.83       149\n",
      "\n",
      "    accuracy                           0.96      1115\n",
      "   macro avg       0.97      0.86      0.91      1115\n",
      "weighted avg       0.96      0.96      0.96      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testando o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1000, gamma='auto')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    x = tfidf.transform([x])\n",
    "    x = x.toarray()\n",
    "    pred = clf.predict(x)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham'], dtype=object)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('Hey, how are you, man? Hope to see you soon next year.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['spam'], dtype=object)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('you have got free tickets.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
